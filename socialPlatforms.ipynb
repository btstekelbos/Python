{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917bed08",
   "metadata": {},
   "source": [
    "# RUN FOR FILES STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c852b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def getDate():\n",
    "    today = datetime.today()\n",
    "    return str(today.strftime('%Y-%m-%d'))\n",
    "    \n",
    "today = getDate()\n",
    "\n",
    "# Creates a url dataframe\n",
    "df_urls = pd.read_excel(\"./url_data.xlsx\")\n",
    "\n",
    "df_urls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d23c01",
   "metadata": {},
   "source": [
    "## Metrics per Social Media Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba54eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facebook\n",
    "j = 0\n",
    "facebook_urls = []\n",
    "\n",
    "for i in df_urls['url_link']:\n",
    "\n",
    "    if df_urls['platform'][j] == \"Facebook\":\n",
    "\n",
    "        facebook_urls.append(i)\n",
    "\n",
    "    j = j+1\n",
    "    \n",
    "# Twitter\n",
    "j = 0\n",
    "twitter_urls = []\n",
    "\n",
    "for i in df_urls['url_link']:\n",
    "\n",
    "    if df_urls['platform'][j] == \"Twitter\":\n",
    "\n",
    "        twitter_urls.append(i)\n",
    "    j = j+1\n",
    "\n",
    "# LinkedIn\n",
    "j = 0\n",
    "linkedin_urls = []\n",
    "\n",
    "for i in df_urls['url_link']:\n",
    "\n",
    "    if df_urls['platform'][j] == \"LinkedIn\":\n",
    "\n",
    "        linkedin_urls.append(i)\n",
    "\n",
    "    j = j+1\n",
    "\n",
    "# Youtube \n",
    "j = 0\n",
    "youtube_urls = []\n",
    "\n",
    "for i in df_urls['url_link']:\n",
    "\n",
    "    if df_urls['platform'][j] == \"Youtube\":\n",
    "        print(df_urls[\"platform\"][j])\n",
    "        youtube_urls.append(i)\n",
    "\n",
    "    j = j+1\n",
    "\n",
    "# Instagram\n",
    "j = 0\n",
    "instagram_urls = []\n",
    "\n",
    "for i in df_urls['url_link']:\n",
    "\n",
    "    if df_urls['platform'][j] == \"Instagram\":\n",
    "        instagram_urls.append(i)\n",
    "\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7d077",
   "metadata": {},
   "source": [
    "## Webscraping\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f68d9",
   "metadata": {},
   "source": [
    "### YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c4152",
   "metadata": {},
   "source": [
    "#### Youtube functions\n",
    "- scrapes youtube data\n",
    "- returns an excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a2fbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/channel/UCnjKxBq90gADBOBAlDvdp6g'\n",
    "\n",
    "def getYT(url=\"\"):\n",
    "\n",
    "    # Instantiates the webdriver, shwowing where the path to the chromedriver is\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # no cookies\n",
    "    # driver.find_element(By.CLASS_NAME, \"nCP5yc\").click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/form[1]/div/div/button').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    # Makes the student hotel page pass over clicking on about due to different formatting\n",
    "    if url != \"https://www.youtube.com/user/TSHbroadcasting/about\":\n",
    "\n",
    "        # click on \"ABOUT\"\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"tabsContent\"]/tp-yt-paper-tab[5]/div').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "    # get number of followers\n",
    "    try:\n",
    "        # get number of followers\n",
    "        subscribers = driver.find_element(By.XPATH, '//*[@id=\"subscriber-count\"]').text\n",
    "\n",
    "        if 'K' in subscribers:\n",
    "            subscribers = re.sub(\"[^0-9]\", \"\")\n",
    "            subscribers = int(subscribers)\n",
    "            subscribers =  1000  * subscribers\n",
    "           \n",
    "        else:\n",
    "            subscribers = subscribers.split()[0]\n",
    "            subscribers = int(subscribers)\n",
    "    except:\n",
    "        subscribers = np.nan\n",
    "\n",
    "    # get total views (Aufrufe - German)\n",
    "    views = driver.find_element(By.XPATH, '//*[@id=\"right-column\"]/yt-formatted-string[3]').text\n",
    "    views = views.split()[0]\n",
    "\n",
    "    # \n",
    "    views = views.replace(\",\", \"\")\n",
    "    views = int(views)\n",
    "    \n",
    "\n",
    "    # click on \"VIDEOS\" - might not work if more videos need to be loaded\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"tabsContent\"]/tp-yt-paper-tab[2]/div').click()\n",
    "    time.sleep(2)\n",
    "        \n",
    "    # get number of posts\n",
    "    try:\n",
    "        # get number of videos\n",
    "        posts = driver.find_elements(By.XPATH, '''//*[@id=\"items\"]//ytd-grid-video-renderer''')\n",
    "        posts = len(posts)\n",
    "        posts = int(posts)\n",
    "    except:\n",
    "        posts = np.nan\n",
    "\n",
    "    # get ratio follower/posts\n",
    "    try: \n",
    "        ratio_fp = subscribers/posts\n",
    "    except:\n",
    "        ratio_fp = np.nan\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    yt_metrices_dict = {\n",
    "        \"number_followers\": subscribers, \n",
    "        \"number_posts\": posts, \n",
    "        \"ratio_follower_posts\": ratio_fp, \n",
    "        \"total_video_views\": views, \n",
    "    }\n",
    "    \n",
    "    return yt_metrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8978ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_gathering(youtube_urls):\n",
    "        youtube_metrics= pd.DataFrame()\n",
    "\n",
    "        for youtube_url in youtube_urls:  \n",
    "\n",
    "                youtube_dictionary = getYT(youtube_url)\n",
    "                youtube_metrics = youtube_metrics.append(youtube_dictionary, ignore_index=True)\n",
    "                youtube_metrics.assign(date=today).set_index('date', append=True).T\n",
    "\n",
    "        return youtube_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5114fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_metrics = youtube_gathering(youtube_urls)\n",
    "youtube_metrics.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317daac3",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c02e3",
   "metadata": {},
   "source": [
    "#### Twitter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28eced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://twitter.com/TheStudentHotel'\n",
    "\n",
    "def getTwitter(url=\"\"):\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"layers\"]/div/div[2]/div/div/div/div[2]/div[2]').click()\n",
    "\n",
    "    try:\n",
    "        num_followers = driver.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[2]/div/div/div/div/div[5]/div[2]/a/span[1]/span').text\n",
    "         # Replaces comma in any value\n",
    "        if \",\" in num_followers:\n",
    "            num_followers = num_followers.replace(\",\",\"\")   \n",
    "            num_followers = int(num_followers)\n",
    "\n",
    "    except:\n",
    "        num_followers = np.nan\n",
    "\n",
    "    try:\n",
    "        num_following = driver.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[2]/div/div/div/div/div[5]/div[1]/a/span[1]/span').text\n",
    "        \n",
    "        if \".\" in num_following:\n",
    "            num_following = num_following.replace(\".\", \"\")\n",
    "            num_following = num_following[:-1]\n",
    "            num_following = int(num_following)\n",
    "\n",
    "        # num_following = float(num_following)\n",
    "    except:\n",
    "        num_following = np.nan\n",
    "\n",
    "    try:\n",
    "        # Attempt at finding number of tweets by boy\n",
    "        num_tweets = driver.find_element(By.XPATH, '//*[@class=\"css-901oao css-1hf3ou5 r-1bwzh9t r-37j5jr r-n6v787 r-16dba41 r-1cwl3u0 r-bcqeeo r-qvutc0\" ]').text\n",
    "\n",
    "        if \" Tweets\" in num_tweets:\n",
    "            num_tweets = re.sub(\"[^0-9]\", \"\", num_tweets)\n",
    "            num_tweets = int(num_tweets)\n",
    "    except:\n",
    "        num_tweets = np.nan\n",
    "\n",
    "    \n",
    "\n",
    "    driver.close()\n",
    "    twitter_metrices_dict = {\n",
    "        \"number_followers\": num_followers, \n",
    "        \"number_following\": num_following, \n",
    "        \"number_tweets\": num_tweets,         \n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return twitter_metrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b86d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes url list \n",
    "# Requires the transform_instagram to have run first.\n",
    "# Gathers data and returns pandas dataframe\n",
    "def twitter_gathering(twitter_urls):\n",
    "        twitter_metrics = pd.DataFrame()\n",
    "        # Gathers, cleans and passes the data into a pandas dataframe\n",
    "        for twitter_url in twitter_urls:\n",
    "\n",
    "                # Maybe makes no sense to do\n",
    "                twitter_row = {}\n",
    "\n",
    "                # Returns a dictionary object\n",
    "                twitter_dictionary = getTwitter(twitter_url)\n",
    "                twitter_metrics = twitter_metrics.append(twitter_dictionary,ignore_index=True)\n",
    "                twitter_metrics.assign(date=today).set_index(\"date\", append=True).T\n",
    "        \n",
    "        # Temporary sleep, since instagram sometimes stops the scraping process\n",
    "        time.sleep(3)\n",
    "\n",
    "        # returns instagram excelsheet\n",
    "        return twitter_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da48a5",
   "metadata": {},
   "source": [
    "### LinkedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e9e4a",
   "metadata": {},
   "source": [
    "#### LinkedIn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15ac588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.linkedin.com/company/the-student-hotel/'\n",
    "\n",
    "def getLI(url=\"\"):   \n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    # Make a function that either goes from sign up page or sign in page and then performs all functions\n",
    "\n",
    "\n",
    "\n",
    "    # First click on sign in to change the webpage\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//button[@class=\"authwall-join-form__form-toggle--bottom form-toggle\"]').click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Inputs username\n",
    "        user_name = driver.find_element(By.XPATH, '//input[@autocomplete=\"username\"]')\n",
    "        user_name.send_keys(\"bt.stekelbos@hotmail.com\")\n",
    "  \n",
    "\n",
    "        # Inputs Password\n",
    "        time.sleep(1)\n",
    "        password = driver.find_element(By.XPATH, '//input[@autocomplete=\"current-password\"]')\n",
    "  \n",
    "        password.send_keys(\"TEMP-PASSWORD\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "\n",
    "         # Clicks the sign in button\n",
    "        driver.find_element(By.XPATH,'//button[@class=\"sign-in-form__submit-button\"]').click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Hop onto the specific page after logging in\n",
    "        driver.get(url)\n",
    "\n",
    "\n",
    "        # Scrape the relevant data which is only follower count\n",
    "        num_followers = driver.find_element(By.XPATH,'//div[@class=\"inline-block\"]').text\n",
    "       \n",
    "        # transforms the text info into number of followers\n",
    "        number_followers = ''\n",
    "        for i in num_followers: \n",
    "            if i.isdigit():\n",
    "                number_followers = number_followers + i\n",
    "        number_followers   = int(number_followers)\n",
    "\n",
    "        num_followers = number_followers\n",
    "    \n",
    "\n",
    "        driver.close()\n",
    "    \n",
    "        li_metrices_dict = {\n",
    "        \"number_followers\": [num_followers], \n",
    "        }\n",
    "\n",
    "        return li_metrices_dict\n",
    "\n",
    "        \n",
    "    # If the landing page changes while looping through the url list it goes through this instead\n",
    "\n",
    "    except:\n",
    "       \n",
    "\n",
    "        # If it lands on sign in page instead do the rest\n",
    "        \n",
    "        # <input id=\"username\" name=\"session_key\" type=\"text\" aria-describedby=\"error-for-username\"\n",
    "        #  required=\"\" validation=\"email|tel\" class=\"\" autofocus=\"\" aria-label=\"Email or Phone\">\n",
    "\n",
    "        # Inputs username\n",
    "        user_name = driver.find_element(By.XPATH, '//input[@oid=\"username\"]')\n",
    "        user_name.send_keys(\"bt.stekelbos@hotmail.com\")\n",
    "  \n",
    "        # <input id=\"password\" type=\"password\" aria-describedby=\"error-for-password\" name=\"session_password\" required=\"\"\n",
    "        #  validation=\"password\" autocomplete=\"current-password\" class=\"\" aria-label=\"Password\">\n",
    "\n",
    "        # Inputs Password\n",
    "        time.sleep(1)\n",
    "        password = driver.find_element(By.XPATH, '//input[@id=\"password\"]')\n",
    "  \n",
    "        password.send_keys(\"weakpassword\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "\n",
    "         # Clicks the sign in button\n",
    "        driver.find_element(By.XPATH,'//button[@class=\"sign-in-form__submit-button\"]').click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Hop onto the specific page after logging in\n",
    "        driver.get(url)\n",
    "\n",
    "\n",
    "        # Scrape the relevant data which is only follower count\n",
    "        num_followers = driver.find_element(By.XPATH,'//div[@class=\"inline-block\"]').text\n",
    "       \n",
    "        # transforms the text info into number of followers\n",
    "        number_followers = ''\n",
    "        for i in num_followers: \n",
    "            if i.isdigit():\n",
    "                number_followers = number_followers + i\n",
    "        number_followers   = int(number_followers)\n",
    "\n",
    "        num_followers = number_followers\n",
    "    \n",
    "\n",
    "        driver.close()\n",
    "    \n",
    "        li_metrices_dict = {\n",
    "        \"number_followers\": num_followers, \n",
    "        }\n",
    "\n",
    "        return li_metrices_dict\n",
    "\n",
    "        # If it lands on sign in page instead do the rest\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4bf8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_gathering(linkedin_urls):\n",
    "        linkedin_metrics = pd.DataFrame()\n",
    "        # Gathers, cleans and passes the data into a pandas dataframe\n",
    "        for linkedin_url in linkedin_urls:\n",
    "                \n",
    "                # Returns a dictionary object\n",
    "                linkedin_dictionary = getLI(linkedin_url)\n",
    "\n",
    "                linkedin_metrics = linkedin_metrics.append(linkedin_dictionary,ignore_index=True)\n",
    "\n",
    "                linkedin_metrics.assign(date=today).set_index(\"date\", append=True).T\n",
    "\n",
    "         # Temporary sleep\n",
    "        time.sleep(3)\n",
    "\n",
    "        # returns linkedin dataframe\n",
    "        return linkedin_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899f637",
   "metadata": {},
   "source": [
    "### Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341462ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWRITE THIS WHOLE THING\n",
    "\n",
    "def facebook_transform(string_list):\n",
    "     # \n",
    "    for value in string_list:\n",
    "        \n",
    "        # Checks for a k in the text and multiplies value by 1000 and adds to list\n",
    "        if 'K' in value:\n",
    "            numerical_instagram= re.sub(\"[^0-9]\", \"\", value)\n",
    "            numerical_instagram = int(numerical_instagram)\n",
    "            value = numerical_instagram * 1000\n",
    "            transformed_values_instagram.append(value)\n",
    "\n",
    "        # transforms string into integer and adds to list object\n",
    "        else:\n",
    "            value = int(value)\n",
    "            transformed_values_instagram.append(value)\n",
    "        \n",
    "    # Returns a list object\n",
    "    return transformed_values_instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad776b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.facebook.com/TheStudentHotelAmsterdamCity/?ref=page_internal'\n",
    "information_list = []\n",
    "def getFB(url=\"\"):   \n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Create a function that clicks only essential cookies\n",
    "    driver.find_element(By.XPATH, '//div[@aria-label=\"Only allow essential cookies\"]').click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    l = driver.find_elements(By.XPATH,\"//*[@class='gvxzyvdx aeinzg81 t7p7dqev gh25dzvf tb6i94ri gupuyl1y i2onq4tn k1z55t6l oog5qr5w tes86rjd pbevjfx6']\")\n",
    "     # filters the list for index 3, 5 and 6, gathering all relevant information\n",
    "    list_facebook = []\n",
    "    for webelement in l:\n",
    "        list_facebook.append(webelement.text)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    list_2 = [list_facebook[0],list_facebook[2],list_facebook[3]]\n",
    "        \n",
    "    return list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not tested\n",
    "for fb_url in links_fb[1:]:\n",
    "    if (fb_url == None):\n",
    "        pass\n",
    "    else:\n",
    "        new_fb = getFB(fb_url)\n",
    "        \n",
    "        for key, value in new_fb.items():\n",
    "            test_fb[key].extend(value)\n",
    "\n",
    "t_fb = pd.DataFrame(test_fb, index = [links_fb]) \n",
    "t_fb.assign(date=today).set_index(\"date\", append=True).T\n",
    "\n",
    "\n",
    "<span class=\"gvxzyvdx aeinzg81 t7p7dqev gh25dzvf tb6i94ri gupuyl1y i2onq4tn k1z55t6l oog5qr5w tes86rjd pbevjfx6\">1,912 people</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1b347",
   "metadata": {},
   "source": [
    "### Instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a8b84",
   "metadata": {},
   "source": [
    "#### Instagram functions\n",
    "- Cleaning instagram data\n",
    "- Scraping information\n",
    "- Gathering all information and returning an excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc415251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes scraped instagram data and cleans it\n",
    "def transform_instagram(string_list):\n",
    "\n",
    "    transformed_values_instagram = []\n",
    "\n",
    "\n",
    "    # \n",
    "    for value in string_list:\n",
    "        \n",
    "        # Checks for a k in the text and multiplies value by 1000 and adds to list\n",
    "        if 'K' in value:\n",
    "            numerical_instagram= re.sub(\"[^0-9]\", \"\", value)\n",
    "            numerical_instagram = int(numerical_instagram)\n",
    "            value = numerical_instagram * 1000\n",
    "            transformed_values_instagram.append(value)\n",
    "\n",
    "        # transforms string into integer and adds to list object\n",
    "        else:\n",
    "            value = int(value)\n",
    "            transformed_values_instagram.append(value)\n",
    "        \n",
    "    # Returns a list object\n",
    "    return transformed_values_instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbc79ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.instagram.com/thestudenthotel/'\n",
    "\n",
    "# Creates a function that takes an URL as input,    \n",
    "def getInsta(url=\"\"):  \n",
    "    \n",
    "    #makes an object of the chrome driver function. \n",
    "    driver = webdriver.Chrome(\"./chromedriver\")\n",
    "\n",
    "    #passes the url into the object and opens the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    #forcibly passes time so the webpage doesnt force a time out\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Create a function that clicks only essential cookies\n",
    "    driver.find_element(By.XPATH, '//button[@class=\"_a9-- _a9_1\"]').click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    # Creates a list of web elements that have the class name _ac2a\n",
    "    l = driver.find_elements(By.CLASS_NAME,'_ac2a')\n",
    "\n",
    "    # Creates list and transform the webelements into text which get put into list_test\n",
    "    list_test = []\n",
    "    for i in l:\n",
    "        list_test.append(i.text)\n",
    "\n",
    "    # Transforms the string information into a list object with all relevant information\n",
    "    clean_data = transform_instagram(list_test)\n",
    "\n",
    "    post_effectiveness = clean_data[0] / clean_data[2]\n",
    "\n",
    "    instagram_dict = {\n",
    "    \"posts\": [clean_data[0]],\n",
    "    \"followers\" : [clean_data[1]],\n",
    "    \"following\" :[clean_data[2]],\n",
    "    \"post_effectivenss\" :[post_effectiveness]\n",
    "    }\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return instagram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4476df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes url list \n",
    "# Requires the transform_instagram to have run first.\n",
    "# Gathers data and returns pandas dataframe\n",
    "def instagram_gathering(instagram_urls):\n",
    "\n",
    "        instagram_metrics = pd.DataFrame()\n",
    "    # Gathers, cleans and passes the data into a pandas dataframe\n",
    "        for insta_url in instagram_urls:\n",
    "                time.sleep(1)\n",
    "\n",
    "                # Maybe makes no sense to do\n",
    "                instagram_row = {}\n",
    "\n",
    "                # Returns a dictionary object\n",
    "                instagram_dictionary = getInsta(insta_url)\n",
    "\n",
    "                # Creates a temporary dictionary looping over every item to get all info\n",
    "                for key, value in instagram_dictionary.items():\n",
    "                        instagram_row[key].extend(value)\n",
    "        \n",
    "        #------- WORK IN PROGRESS----------------#\n",
    "                # RUN TOMORROW\n",
    "\n",
    "\n",
    "                instagram_metrics = instagram_metrics.append(instagram_row, ignore_index = True)\n",
    "\n",
    "                instagram_metrics.assign(date=today).set_index(\"date\", append=True).T\n",
    "\n",
    "        \n",
    "        #------- WORK IN PROGRESS----------------#\n",
    "\n",
    "    \n",
    "        \n",
    "        # Temporary sleep, since instagram sometimes stops the scraping process\n",
    "        time.sleep(3)\n",
    "\n",
    "        # returns dictionary\n",
    "        return instagram_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a350c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over every url for instagram and add to pandas dataframe\n",
    "\n",
    "# creates a dataframe to put all lists in\n",
    "\n",
    "# loops over every url \n",
    "for insta_url in instagram_urls:\n",
    "\n",
    "    # Returns a list object not a dict, so maybe return a dict instead and copy code that's already here\n",
    "    new_insta = getInsta(insta_url)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for key, value in new_insta.items():\n",
    "    #         test_insta[key].extend(value)\n",
    "           \n",
    "\n",
    "    transformed_values_instagram = []\n",
    "    \n",
    "    for value in new_insta:\n",
    "        if 'K' in value:\n",
    "            numerical_instagram= re.sub(\"[^0-9]\", \"\", value)\n",
    "            numerical_instagram = int(numerical_instagram)\n",
    "            value = numerical_instagram * 1000\n",
    "            transformed_values_instagram.append(value)\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            value = value.replace(\",\",\"\")\n",
    "            value = int(value)\n",
    "            transformed_values_instagram.append(value)\n",
    "        \n",
    "\n",
    "    \n",
    "    instagram_dict = {}\n",
    "\n",
    "    instagram_dict['posts'] = [transformed_values_instagram[0]]\n",
    "    instagram_dict[\"followers\"] = [transformed_values_instagram[1]]\n",
    "    instagram_dict['following'] = [transformed_values_instagram[2]]\n",
    "\n",
    "    print(instagram_dict)\n",
    "\n",
    "\n",
    "    # Iterates but overrides the values in the pandas dataframe , so to fix make append true?\n",
    "\n",
    "    instagram_df = pd.DataFrame.from_dict(instagram_dict,orient=\"columns\")\n",
    "    \n",
    "\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "instagram_df.head()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d854cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30K followers, 408 following, 901 posts – see Instagram photos and videos from The Student Hotel (@thestudenthotel)\n",
      "['30', '408', '901']\n"
     ]
    }
   ],
   "source": [
    "# Converts a full line of text into a dictionary that can be transformed or input into a dataframe\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "instagram_split = test_insta.split(\",\")\n",
    "\n",
    "numeric_instagram_split  = []\n",
    "for list_value in instagram_split:\n",
    " \n",
    "\n",
    "\n",
    "    numerical_instagram= re.sub(\"[^0-9]\", \"\", list_value)\n",
    "    numeric_instagram_split.append(numerical_instagram)\n",
    "    \n",
    "    # numeric_instagram_split.append(numerical_instagram)\n",
    "\n",
    "\n",
    "print(numeric_instagram_split)\n",
    "\n",
    "dictionary_keys = [\"Number of followers\",\"Number of following\", \"Number of posts\"]\n",
    "\n",
    "instagram_dictionary = dict(zip(dictionary_keys,numeric_instagram_split))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not tested\n",
    "# loops over the instagram url list, skips over the first urL? \n",
    "\n",
    "\n",
    "# REDO : RECREATE LINKS LIST INTO A CONGLORERATION OF ALL PLATFORM LINKS INTO ONE PANDAS DATAFRAME\n",
    "# Loop over \n",
    "####for insta_url in df['instagram'][1:]\n",
    "\n",
    "for insta_url in links_insta[1:]:\n",
    "    # Why check whether there's no value when you're passing the value in there?\n",
    "    if (insta_url == None):\n",
    "        pass\n",
    "    # Runs the function to gather information and returns a dictionairy, which new_insta inherits\n",
    "    else:\n",
    "        new_insta = getInsta(insta_url)\n",
    "        \n",
    "        # Loops over every metric of key and value within the dicitionairy \n",
    "        for key, value in new_insta.items():\n",
    "\n",
    "            # Not sure what this does\n",
    "            test_insta[key].extend(value)\n",
    "\n",
    "\n",
    "# Makes a dataframe for the data gathered and indexes them based on url\n",
    "t_insta = pd.DataFrame(test_insta, index = [links_insta]) \n",
    "\n",
    "#assigns time of date to the pandas dataframe\n",
    "t_insta.assign(date=today).set_index(\"date\", append=True).T\n",
    "\n",
    "# Example of writing it out:\n",
    "t_insta.to_excel(\"Instagram information.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TO DO:\n",
    "# CHECK IF DIVS ARE WORKING \n",
    "# Facebook webscraping converts values into text but instagram scraping converts them into floats? why make that difference\n",
    "# Get youtube webscraping to work and generate a pandas dataframe it breaks after clicking on the about button\n",
    "\n",
    "\n",
    "# FIXED ----- Wrote a line to write the existing dataframe into an excel file\n",
    "# Cant find any code to write this out into an excel file\n",
    "\n",
    "\n",
    "# FIXED ---- Rewrote the database in excel and then transformed it into a pandas df, simple filter generates a url list now.\n",
    "# Check the ranges with which the url links are being generated\n",
    "\n",
    "\n",
    "# FIXED ---- Rewrote the database in excel and then transformed it into a pandas df, simple filter generates a url list now.\n",
    "# Fix youtube url gathering from excel, its pulling linkedin url and only 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad429f0",
   "metadata": {},
   "source": [
    "# RUN FOR FILES STEP 2\n",
    "\n",
    "NOTES:\n",
    "- SHOULD EVENTUALLY RETURN AN EXCEL SHEET FILE WHICH AUTOMATTICALY STARTS DOWNLOADING\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85e34b",
   "metadata": {},
   "source": [
    "## Run for Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = url = 'https://www.instagram.com/thestudenthotel/'\n",
    "instagram = getInsta(url)\n",
    "\n",
    "print(instagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ec28d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/1098962209.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"./chromedriver\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"./chromedriver\")\n",
    "driver.get('https://www.instagram.com/accounts/login/?next=%2Fthestudenthotel%2F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e9cd817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/1890813414.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"./chromedriver\")\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//button[@class=\"_a9-- _a9_1\"]\"}\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\n0   chromedriver                        0x0000000101191a90 chromedriver + 3889808\n1   chromedriver                        0x0000000101120b54 chromedriver + 3427156\n2   chromedriver                        0x0000000100e12238 chromedriver + 221752\n3   chromedriver                        0x0000000100e434c8 chromedriver + 423112\n4   chromedriver                        0x0000000100e6c944 chromedriver + 592196\n5   chromedriver                        0x0000000100e3854c chromedriver + 378188\n6   chromedriver                        0x00000001011652f8 chromedriver + 3707640\n7   chromedriver                        0x0000000101168ea8 chromedriver + 3722920\n8   chromedriver                        0x000000010116f3d8 chromedriver + 3748824\n9   chromedriver                        0x00000001011699a8 chromedriver + 3725736\n10  chromedriver                        0x0000000101144de8 chromedriver + 3575272\n11  chromedriver                        0x0000000101183d1c chromedriver + 3833116\n12  chromedriver                        0x0000000101183e84 chromedriver + 3833476\n13  chromedriver                        0x0000000101198210 chromedriver + 3916304\n14  libsystem_pthread.dylib             0x00000001a72fd240 _pthread_start + 148\n15  libsystem_pthread.dylib             0x00000001a72f8024 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000051?line=0'>1</a>\u001b[0m \u001b[39m# SHOULD EVENTUALLY RETURN AN EXCEL SHEET FILE WHICH AUTOMATTICALY STARTS DOWNLOADING\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000051?line=1'>2</a>\u001b[0m instagram_metrics \u001b[39m=\u001b[39m instagram_gathering(instagram_urls)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000051?line=2'>3</a>\u001b[0m instragam_metrics\u001b[39m.\u001b[39mhead()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000051?line=3'>4</a>\u001b[0m instagram_metrics\u001b[39m.\u001b[39mto_excel(\u001b[39m\"\u001b[39m\u001b[39mInstagram_information.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb Cell 49'\u001b[0m in \u001b[0;36minstagram_gathering\u001b[0;34m(instagram_urls)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000043?line=11'>12</a>\u001b[0m instagram_row \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000043?line=13'>14</a>\u001b[0m \u001b[39m# Returns a dictionary object\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000043?line=14'>15</a>\u001b[0m instagram_dictionary \u001b[39m=\u001b[39m getInsta(insta_url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000043?line=16'>17</a>\u001b[0m \u001b[39m# Creates a temporary dictionary looping over every item to get all info\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000043?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m instagram_dictionary\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;32m/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb Cell 48'\u001b[0m in \u001b[0;36mgetInsta\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000042?line=12'>13</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000042?line=14'>15</a>\u001b[0m \u001b[39m# Create a function that clicks only essential cookies\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000042?line=15'>16</a>\u001b[0m driver\u001b[39m.\u001b[39;49mfind_element(By\u001b[39m.\u001b[39;49mXPATH, \u001b[39m'\u001b[39;49m\u001b[39m//button[@class=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_a9-- _a9_1\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mclick()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000042?line=16'>17</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/boystekelbos/Documents/Programming/Webscraping/social_media_scraping_advanced.ipynb#ch0000042?line=18'>19</a>\u001b[0m \u001b[39m# Creates a list of web elements that have the class name _ac2a\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:855\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=851'>852</a>\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=852'>853</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[0;32m--> <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=854'>855</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENT, {\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=855'>856</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m'\u001b[39;49m: by,\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=856'>857</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m: value})[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=425'>426</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=426'>427</a>\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=427'>428</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=428'>429</a>\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=429'>430</a>\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py?line=430'>431</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py?line=240'>241</a>\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py?line=241'>242</a>\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/boystekelbos/Documents/Programming/.env/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py?line=242'>243</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//button[@class=\"_a9-- _a9_1\"]\"}\n  (Session info: chrome=105.0.5195.125)\nStacktrace:\n0   chromedriver                        0x0000000101191a90 chromedriver + 3889808\n1   chromedriver                        0x0000000101120b54 chromedriver + 3427156\n2   chromedriver                        0x0000000100e12238 chromedriver + 221752\n3   chromedriver                        0x0000000100e434c8 chromedriver + 423112\n4   chromedriver                        0x0000000100e6c944 chromedriver + 592196\n5   chromedriver                        0x0000000100e3854c chromedriver + 378188\n6   chromedriver                        0x00000001011652f8 chromedriver + 3707640\n7   chromedriver                        0x0000000101168ea8 chromedriver + 3722920\n8   chromedriver                        0x000000010116f3d8 chromedriver + 3748824\n9   chromedriver                        0x00000001011699a8 chromedriver + 3725736\n10  chromedriver                        0x0000000101144de8 chromedriver + 3575272\n11  chromedriver                        0x0000000101183d1c chromedriver + 3833116\n12  chromedriver                        0x0000000101183e84 chromedriver + 3833476\n13  chromedriver                        0x0000000101198210 chromedriver + 3916304\n14  libsystem_pthread.dylib             0x00000001a72fd240 _pthread_start + 148\n15  libsystem_pthread.dylib             0x00000001a72f8024 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "# SHOULD EVENTUALLY RETURN AN EXCEL SHEET FILE WHICH AUTOMATTICALY STARTS DOWNLOADING\n",
    "instagram_metrics = instagram_gathering(instagram_urls)\n",
    "instragam_metrics.head()\n",
    "instagram_metrics.to_excel(\"Instagram_information.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124d5a3",
   "metadata": {},
   "source": [
    "## Run for Youtube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_metrics = youtube_gathering(youtube_urls)\n",
    "youtube_metrics.head()\n",
    "youtube_metrics.to_excel(\"Youtube_information.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4797d8",
   "metadata": {},
   "source": [
    "## Run for Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "065e4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/1078140683.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/755140697.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  twitter_metrics = twitter_metrics.append(twitter_dictionary,ignore_index=True)\n",
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/1078140683.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/755140697.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  twitter_metrics = twitter_metrics.append(twitter_dictionary,ignore_index=True)\n",
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/1078140683.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"./chromedriver\")\n",
      "/var/folders/_1/99j0wl7d7l9btzc9rfh821t40000gn/T/ipykernel_5644/755140697.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  twitter_metrics = twitter_metrics.append(twitter_dictionary,ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_followers</th>\n",
       "      <th>number_following</th>\n",
       "      <th>number_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683</td>\n",
       "      <td>688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489</td>\n",
       "      <td>494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  number_followers number_following  number_tweets\n",
       "0             2683              688            NaN\n",
       "1              194              140            NaN\n",
       "2              489              494            NaN"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_metrics = twitter_gathering(twitter_urls)\n",
    "twitter_metrics.to_excel(\"Twitter_Information.xlsx\")\n",
    "twitter_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416bdd5",
   "metadata": {},
   "source": [
    "## Run for LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1139149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_metrics.to_excel(\"Twitter_information.xlsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_metrics = linkedin_gathering(linkedin_urls)\n",
    "linkedin_metrics.head()\n",
    "linkedin_metrics.to_excel(\"LinkedIn_information.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daeac6d63815b337cdbc63cd820bf487f6113d664477cbf77ebc43f6393e9675"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
